{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c932066-73d1-4d7f-955c-7b49f1aaab9c",
      "metadata": {},
      "source": [
        "# Decision Trees\n",
        "55377f5b65d7c82726ee8a0460)\r\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc3cfb9-c0a0-4c3a-9158-fe38b1ed5cc3",
      "metadata": {},
      "source": [
        "Student: Noa Pereira Prada Schnor\n",
        "\n",
        "Student ID: A00326381"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1fa4c5a-9cb4-4605-bf23-dc983cd15dd7",
      "metadata": {},
      "source": [
        "### Dataset Overview:\n",
        "#### Name: Estimation of Obesity Levels Based On Eating Habits and Physical Condition\n",
        "#### Purpose:\n",
        "This dataset is primarily used to estimate obesity levels among individuals from Mexico, Peru, and Colombia by analysing their eating habits and physical activity.\n",
        "#### Data Generation:\n",
        "- **77%** of the data was generated **synthetically** using the **Weka** tool and the **SMOTE** filter, while **23%** of the data was **collected directly** from users via a **web platform**.\n",
        "    \n",
        "#### Target Variable:\n",
        "- **Name:** NObeyesdad\n",
        "- **Description:** Ordinal variable created based on the **Body Mass Index (BMI)**. The dataset classifies individuals into 7 NObeyesdad categories, from Insufficient Weight to Obesity Type III.\n",
        "\n",
        "#### Feature Variables:\n",
        "The feature variables are related to eating habits attributes, physical activity attributes and additional attributes, such as gender and age. All the attributes are listed below.\n",
        "\n",
        "##### Eating Habits Attributes:\n",
        "The following attributes are related to the **eating habits** of individuals:\n",
        "- **Frequent consumption of high-caloric food (FAVC)** - binary: Yes/No\n",
        "- **Frequency of consumption of vegetables (FCVC)** - categorical: Never, Sometimes, Always\n",
        "- **Number of main meals (NCP)** - categorical: Between 1 and 2, Three, More than three\n",
        "- **Consumption of food between meals (CAEC)** -categorical: No, Sometimes, Frequently, Always\n",
        "- **Consumption of water daily (CH20)** -categorical: Less than a litre, Between 1 and 2 L, More than 2 L\n",
        "- **Consumption of alcohol (CALC)**\n",
        "\n",
        "##### Physical Activity Attributes:\n",
        "The attributes related to the **physical activity** of individuals include:\n",
        "- **Calories consumption monitoring (SCC)** - binary: Yes/No\n",
        "- **Physical activity frequency (FAF)** - categorical: I do not have, 1 or 2 days, 2 or 4 days, 4 or 5 days\n",
        "- **Time using technology devices (TUE)** - categorical: 0\u20132 hours, 3\u20135 hours, More than 5 hours\n",
        "- **Transportation used (MTRANS)** - categorical: Automobile, Motorbike, Bike, Public Transportation, Walking\n",
        "\n",
        "\n",
        "##### Additional Attributes:\n",
        "Other variables obtained in the dataset are:\n",
        "- **Gender** - binary: Male/Female\n",
        "- **Age** - numerical, in years\n",
        "- **Height** - numerical, in metres\n",
        "- **Weight** - numerical, in kilograms\n",
        "- **Smoke(SMOKE)** - binary: yes/no\n",
        "- **Family History of Obesity(family_history_with_overweight)** - binary: Yes/No\n",
        "\n",
        "\n",
        "#### Additional Resources:\n",
        "For detailed information and studies related to this dataset, please refer to the following sources:\n",
        "- [UCI Machine Learning Repository: Estimation of Obesity Levels Based On Eating Habits and Physical Condition Dataset](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition)\n",
        "- [Dataset for Estimation of Obesity Levels Based on Eating Habits and Physical Condition](https://www.semanticscholar.org/paper/Dataset-for-estimation-of-obesity-levels-based-on-Palechor-Manotas/35b40bacd2ffa9370885b7a3004d88995fd1d011)\n",
        "- The full paper can be accessed from [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6710633/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "143365a2-d8b0-43a3-9a94-c9aeb706db79",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38312f80-d5da-4753-bc8b-dc84ffc0e30e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split #to split into the training and test data\n",
        "from sklearn import metrics #to calculate accuracy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix #to check the prediction expected vs predicted\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import export_graphviz\n",
        "from io import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce7f811-0ba7-4d46-86ba-a74a583b4f6b",
      "metadata": {},
      "source": [
        "### Load Data and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687ba7ba-b025-4606-87d6-636320e89e3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Read the csv file\n",
        "df = pd.read_csv(\"data/ObesityDataSet_raw_and_data_sinthetic.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3acde7c-b75b-471b-a071-660272b10351",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Check first  rows of the dataset\n",
        "df.head() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5cc25c-955f-469b-ad52-13470f161c11",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "- The target variable (Nobeyesdad) is a categorical/ordinal variable\n",
        "- Features: mixed data type - categorical, binary, and continuous (numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fecf7a-0834-4265-9512-550f017a3d63",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Check number of instances and columns\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0803226-bc42-425a-ad66-8c55bd09d58d",
      "metadata": {},
      "source": [
        "- Instances: 2111\n",
        "- No. columns: 17 (including the Target variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2af02c-c675-46e1-b557-3d74f4a12ea3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Check the data type\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f448a58-5bda-4873-b2d9-2d65e5a25768",
      "metadata": {},
      "source": [
        "- No missing data\n",
        "- All columns with 2111 data entries/instances\n",
        "- 9 Non-numerical columns with Dtype 'object' - categorical\n",
        "- 8 Numerical columns float-type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc281ce-ec7c-4533-a124-6e644406fda2",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Check the statistical summary of numerical columns\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92a162e-2921-4d73-afdf-7f980a4e3a6e",
      "metadata": {},
      "source": [
        "-  Data spread: wide spread of Weight (from 39 to 173 kg)\n",
        "-  It seems that not only adults are included in this dataset, the Age ranges from 14 to 61"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db25f1d-4cb6-47be-9a2c-1f6cb9930294",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Check the distributions of the categories of the target variable\n",
        "print(df.NObeyesdad.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7bcce23-7709-4793-a549-838e59cf4b55",
      "metadata": {},
      "source": [
        "- Fairly balanced distribution across Obesity Level categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5f87a5-5627-4646-a8c1-2f5cbe5e130d",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Explore the relationships among numerical variables\n",
        "scatter_matrix(df, figsize=(10, 10), diagonal='kde')  # 'kde' to show kernel density on the diagonal\n",
        "# Save the figure\n",
        "plt.savefig('plots/DecisionTrees/DT_scatter_matrix.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "debc07d0-b697-4ddf-9f6b-757c96264aeb",
      "metadata": {},
      "source": [
        "- Age distribution - right-skewed: most individuals are younger with fewer older individuals\n",
        "- Height/Weight more normal-like distribution\n",
        "- Variables like FCVC, NCP, and CH2O have distinct peaks, suggesting certain preferences or habits may dominate the dataset (like eating habits or water consumption). \n",
        "- There don\u2019t appear to be strong linear relationships between these lifestyle factors and physical attributes like height, weight, or age.\n",
        "- Weight vs. Age: older individuals possibly weigh more, but there doesn\u2019t appear to be a strong correlation.\n",
        "- Weight vs. Height: positive correlation, as expected. Taller individuals generally weigh more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be43cb5e-48e5-4ce9-af64-778a352a94bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define mappings\n",
        "frequency_mapping = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
        "binary_mapping = {'no': 0, 'yes': 1}\n",
        "\n",
        "# Columns to map\n",
        "frequency_columns = ['CALC', 'CAEC']\n",
        "binary_columns = ['family_history_with_overweight', 'SMOKE', 'FAVC', 'SCC']\n",
        "\n",
        "# Apply mappings to frequency columns\n",
        "for col in frequency_columns:\n",
        "    # Convert column to lowercase string and map\n",
        "    df[col] = df[col].astype(str).map(frequency_mapping)\n",
        "    \n",
        "    # Check for any missing values introduced by the mapping\n",
        "    print(f\"Column {col} missing values after mapping:\", df[col].isna().sum())\n",
        "\n",
        "# Apply mappings to binary columns\n",
        "for col in binary_columns:\n",
        "    # Convert column to lowercase string and map\n",
        "    df[col] = df[col].astype(str).map(binary_mapping)\n",
        "    \n",
        "    # Check for any missing values introduced by the mapping\n",
        "    print(f\"Column {col} missing values after mapping:\", df[col].isna().sum())\n",
        "\n",
        "# Combine transformed columns\n",
        "transformed_columns = frequency_columns + binary_columns\n",
        "\n",
        "\n",
        "# One-hot encode 'MTRANS' and 'Gender' in one line\n",
        "df = pd.get_dummies(df, columns=['MTRANS', 'Gender'], prefix=['MTRANS', 'Gender'])\n",
        "\n",
        "# Check the first 5 rows of the transformed DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f90e107-5bad-40a7-bf4e-3a05c3112d4c",
      "metadata": {},
      "source": [
        "- Categorical features were encoded\n",
        "- Target variable is an ordinal variable and not encoded. The model will be run with not encoded and encoded target variable to check what is the best approach with the target variable (it should encoded or not to get a better model performance?)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f339ad-9940-4c27-afac-0b77b2336da8",
      "metadata": {},
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3ab4a2-43ad-417b-960f-1520917ba2ac",
      "metadata": {},
      "source": [
        "#### Non encoded target variable (NObeyesdad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5617a788-ec0c-4b6b-aad7-f58b412e0b2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the features\n",
        "X = df.drop(['NObeyesdad'], axis=1)  # Dropping the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70d28b1-b423-41fa-abfa-a53d49196554",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Defining the target variable\n",
        "y = df['NObeyesdad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738447e4-3c59-4742-851d-33963d7c5f71",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Splitting the data (training, test data)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=1,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8de207-e625-4fd9-a075-4f7e6d4f4e93",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create the model and fit the training data\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a13ee7-9871-48b8-aebf-9ee4bc4b8767",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predict the response for test dataset\n",
        "y_hat = tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35884c0f-6a16-47ea-a8e8-c21c62a808f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model Accuracy, how often is the classifier correct?\n",
        "accuracy = metrics.accuracy_score(y_test, y_hat)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2cf6346-090b-4839-a08f-70ebaa9a3f63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the depth of the tree after fitting\n",
        "print(f\"Depth of the tree: {tree.get_depth()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58414b4a-983e-4c5e-8680-b22b72c31dae",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Create cm for a non-encoded target variable \n",
        "\n",
        "feature_names = X.columns\n",
        "print(feature_names)\n",
        "\n",
        "target_names = [\"Obesity_Type_I\", \"Obesity_Type_II\",\"Obesity_Type_III\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Normal_Weight\", \"Insufficient_Weight\"] #name of all possible values for obesity field\n",
        "\n",
        "#Confusion matrix\n",
        "cm= confusion_matrix(y_test,y_hat)\n",
        "\n",
        "# Convert the confusion matrix to a DataFrame with target names as row and column labels\n",
        "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
        "\n",
        "# Print the confusion matrix with labels\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9841d6ed-9deb-45bc-9817-ae92ae820e5e",
      "metadata": {},
      "source": [
        "- Good classification ability, especially in categories like Obesity_Type_III and Overweight_Level_II, where correct classification rates are very high.\n",
        "- The misclassifications happen between normal weight and insufficient weight, and obesity I and II."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96fdca56-2940-49b1-a945-c66c4c00650c",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Check the splits, gini values, and how the features were used of all the levels\n",
        "dot_data = StringIO()\n",
        "\n",
        "# Corrected export_graphviz call\n",
        "export_graphviz(\n",
        "    tree, \n",
        "    out_file=dot_data, \n",
        "    filled=True, \n",
        "    rounded=True,  # Capital \"T\"\n",
        "    special_characters=True,  # Correct spelling\n",
        "    feature_names=feature_names, \n",
        "    class_names=target_names\n",
        ")\n",
        "\n",
        "# Creating the graph from dot data\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "\n",
        "#save figure\n",
        "graph.write_png('plots/DecisionTrees/obesityDecisionTree_not_encoded.png')\n",
        "\n",
        "\n",
        "# Displaying the image\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d60ae5-4c29-4aa5-9fe9-73d44ba911b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform 5-fold cross-validation on the decision tree model and print the accuracy for each fold\n",
        "scores = cross_val_score(tree, X_train, y_train, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4eba59-ac49-4898-a885-173921ecd260",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the accuracy scores for each fold to see the model's performance on each subset of the data\n",
        "print(scores)\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds to get an overall cross-validation accuracy estimate\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0098610-0e37-4d90-9ccc-2807aeb1e710",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Cross-validation helps ensure that the model generalizes well to unseen data. \n",
        "\n",
        "accuracy_depths = []\n",
        "\n",
        "# Loop through the depths and calculate both cross-validation and training accuracy\n",
        "for d in range(1, 20):\n",
        "    tree = DecisionTreeClassifier(max_depth=d)\n",
        "    \n",
        "    # Cross-validation accuracy (using 5-fold CV)\n",
        "    scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
        "    mean_cv_score = scores.mean()\n",
        "    \n",
        "    # Fit the model on the full training set to compute training accuracy\n",
        "    tree.fit(X_train, y_train)\n",
        "    train_predictions = tree.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    \n",
        "    # Store both accuracies and the depth\n",
        "    accuracy_depths.append((mean_cv_score, train_accuracy, d))\n",
        "    \n",
        "    # Printing the CV and Training accuracies\n",
        "    print(f\"Depth {d}: Cross Validation Accuracy = {mean_cv_score:.4f}, Training Accuracy = {train_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# Finding the maximum cross-validation accuracy\n",
        "max_accuracy = max(accuracy_depths, key=lambda x: x[0])[0]\n",
        "\n",
        "# Finding all depths that have the maximum accuracy\n",
        "best_depths = [d for cv_score, train_accuracy, d in accuracy_depths if cv_score == max_accuracy]\n",
        "\n",
        "# Printing the depth with the highest Cross Validation accuracy \n",
        "print(f\"\\nMaximum Cross-Validation Accuracy: {max_accuracy:.4f} at Depth(s): {best_depths}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19127e36-98c6-4393-90c3-a05662644ab6",
      "metadata": {},
      "source": [
        "- The Best Cross-Validation accuracy is at Depth 11, however, the training accuracy reaches 100% from depth 11, and the cross-validation does not change much from depth 10. To avoid overfitting the depth 10 could be chosen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ca5dd2f-17fd-4369-9a4c-014073631734",
      "metadata": {},
      "source": [
        "#### Encoded target variable (NObeyesdad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97446216-1bb0-4133-84c3-ba4483c2381c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Encoding the target variable to check if there is any change/improvement in the model performance\n",
        "\n",
        "#Check unique values of the target variable\n",
        "print(df['NObeyesdad'].unique())\n",
        "\n",
        "#Category order mapping\n",
        "category_order = {\n",
        "    'Insufficient_Weight': 0,\n",
        "    'Normal_Weight': 1,\n",
        "    'Overweight_Level_I': 2,\n",
        "    'Overweight_Level_II': 3,\n",
        "    'Obesity_Type_I': 4,\n",
        "    'Obesity_Type_II': 5,\n",
        "    'Obesity_Type_III': 6\n",
        "}\n",
        "\n",
        "#Assign digits to the target variable\n",
        "y_encoded = df['NObeyesdad'].map(category_order)\n",
        "\n",
        "#Check the encoded target variable\n",
        "print(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c0661d-469b-4e8b-bde7-266f54cb3341",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Splitting the data (training, test data)\n",
        "X_train,X_test,y_train_encoded,y_test_encoded = train_test_split(X,y_encoded,test_size=0.25,random_state=1,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56b4a76-7459-440f-8c6c-1c2d8abe62e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create the model and fit the training data\n",
        "tree_encoded = DecisionTreeClassifier()\n",
        "tree_encoded.fit(X_train,y_train_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c4ec36-573c-4235-89a2-ec55d5c71694",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predict the response for the test dataset\n",
        "y_hat_encoded = tree_encoded.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "092aa504-b233-43fd-ad5a-2d1a1e300a6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model Accuracy, how often is the classifier correct?\n",
        "accuracy_encoded = metrics.accuracy_score(y_test_encoded, y_hat_encoded)\n",
        "print(\"Accuracy:\", accuracy_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059c7a9d-bfd1-4e40-abbf-d74fe5dea567",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the depth of the tree after fitting\n",
        "print(f\"Depth of the tree: {tree_encoded.get_depth()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1183e5b-5d4c-4ffb-b488-6d688c1df03f",
      "metadata": {},
      "source": [
        "- The model seems to behave quite similarly to the encoded target variable (same depth).\n",
        "- The model score had a slight improvement (from 0.9318 to 0.9337)\n",
        "- The model handles well categorical target variable\n",
        "- The model was able to capture most patterns even without explicit ordinal encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3908980a-5837-42f3-84b8-6e811acbd4b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_encoded = cross_val_score(tree_encoded, X_train, y_train_encoded, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ad9e3c-c6d8-4266-a213-f20263df584c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(scores_encoded)\n",
        "print(scores_encoded.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360ab0b3-273e-4db9-a0f3-5507bee40628",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation helps ensure that the model generalizes well to unseen data.\n",
        "accuracy_depths_encoded = []\n",
        "\n",
        "# Loop through the depths and calculate both cross-validation and training accuracy\n",
        "for d in range(1, 20):\n",
        "    tree_encoded = DecisionTreeClassifier(max_depth=d)\n",
        "    \n",
        "    # Cross-validation accuracy (using 5-fold CV)\n",
        "    scores_encoded = cross_val_score(tree_encoded, X_train, y_train_encoded, cv=5)\n",
        "    mean_cv_score_encoded = scores_encoded.mean()\n",
        "    \n",
        "    # Fit the model on the full training set to compute training accuracy\n",
        "    tree_encoded.fit(X_train, y_train_encoded)\n",
        "    train_predictions_encoded = tree_encoded.predict(X_train)\n",
        "    train_accuracy_encoded = accuracy_score(y_train_encoded, train_predictions_encoded)\n",
        "    \n",
        "    # Store both accuracies and the depth\n",
        "    accuracy_depths_encoded.append((mean_cv_score_encoded, train_accuracy_encoded, d))\n",
        "    \n",
        "    # Printing the CV and Training accuracies\n",
        "    print(f\"Depth {d}: Cross Validation Accuracy = {mean_cv_score_encoded:.4f}, Training Accuracy = {train_accuracy_encoded:.4f}\")\n",
        "\n",
        "# Finding the maximum cross-validation accuracy\n",
        "max_accuracy_encoded = max(accuracy_depths_encoded, key=lambda x: x[0])[0]\n",
        "\n",
        "# Finding all depths that have the maximum accuracy\n",
        "best_depths_encoded = [d for cv_score_encoded, train_accuracy_encoded, d in accuracy_depths_encoded if cv_score_encoded == max_accuracy_encoded]\n",
        "\n",
        "# Printing the depth with the highest Cross Validation accuracy \n",
        "print(f\"\\nMaximum Cross-Validation Accuracy: {max_accuracy_encoded:.4f} at Depth(s): {best_depths_encoded}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a99443cf-f3b2-4be2-bef1-ca2b8692062e",
      "metadata": {},
      "source": [
        "#### Checking the cross-validation accuracy of encoded vs non-encoded target variable:\n",
        "- Encoding the target as integers for ordinal relationships provides a slight advantage in cross-validation accuracy.\n",
        "- Both cases (encoded and non-encoded target variable) overfit at greater depths is valuable for tuning your model.\n",
        "- The best depth for encoded seems to be 13, however, the Training accuracy reaches 100% at depth 11 while the Cross-Validation accuracy does not change significantly.\n",
        "- As the tree gets deeper, it can handle more complex decision boundaries, but this comes with the risk of overfitting, which was evident in the training and cross-validation accuracy results.\n",
        "- The depth to be used should be 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68771c8d-fb7e-4c80-b3f3-bbc28a44b4e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create the model and fit the training data\n",
        "tree_encoded = DecisionTreeClassifier(max_depth=10)\n",
        "tree_encoded.fit(X_train,y_train_encoded)\n",
        "#Predict the response for the test dataset\n",
        "y_hat_encoded = tree_encoded.predict(X_test)\n",
        "\n",
        "#Model Accuracy, how often is the classifier correct?\n",
        "accuracy_encoded = metrics.accuracy_score(y_test_encoded, y_hat_encoded)\n",
        "print(\"Accuracy:\", accuracy_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bb6f97-f0fa-45a4-bfde-46c2d4d3fcff",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Check the splits, gini values, and how the features were used of all the levels\n",
        "dot_data = StringIO()\n",
        "\n",
        "# Corrected export_graphviz call\n",
        "export_graphviz(\n",
        "    tree, \n",
        "    out_file=dot_data, \n",
        "    filled=True, \n",
        "    rounded=True,  # Capital \"T\"\n",
        "    special_characters=True,  # Correct spelling\n",
        "    feature_names=feature_names, \n",
        "    class_names=target_names\n",
        ")\n",
        "\n",
        "# Creating the graph from dot data\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "\n",
        "#save figure\n",
        "graph.write_png('plots/DecisionTrees/obesityDecisionTree_depth10_encoded.png')\n",
        "\n",
        "\n",
        "# Displaying the image\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68061cc-d1d9-4127-ac68-5c692c3bf031",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Create a cm for a encoded target variable\n",
        "\n",
        "# Create a list of labels in the correct order\n",
        "labels = list(category_order.keys())\n",
        "\n",
        "cm_encoded = confusion_matrix(y_test_encoded, y_hat_encoded)\n",
        "\n",
        "# Create the DataFrame with the category names as labels\n",
        "cm_df = pd.DataFrame(cm_encoded, index=labels, columns=labels)\n",
        "\n",
        "# Print the confusion matrix with readable labels\n",
        "print(\"Confusion Matrix with Labels:\")\n",
        "print(cm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911f837e-e1d7-47d8-bf5d-0b2943b3f751",
      "metadata": {},
      "source": [
        "- If the model needs to consider the ordinal nature explicitly, the encoded target should be chosen. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1451f31-7d84-4c31-b305-ba3c35b6125b",
      "metadata": {},
      "source": [
        "## The end"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}